sim: &sim !SimConfig
  ped_model: none
  control_lb: (0., 0.)
  control_ub: (2., 2.826)  # 0.9 * pi
  goal_reach_threshold: 0.1
  max_steps: 300


agents:  &agents !RobotOnlySampler
  sampling_square: (20, 20)
  min_robot_goal_distance: 5.0


reward: &reward !BranchReward
  success_reward: 10.
  fail_reward: -20.
  step_reward: !PotentialGoalReward
    coefficient: 2.
  truncated_is_fail: false


train_env_factory: !SimpleNavEnvFactory
  agents_sampler: *agents
  reward: *reward
  sim_config: *sim
  normalize_actions: true
  render: false
